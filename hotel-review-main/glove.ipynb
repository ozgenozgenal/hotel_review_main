{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              hotel_name hotel_city  review_date  \\\n",
      "0  are_dubai_abc_almanar_hotel_apartment      dubai  Oct 26 2009   \n",
      "1  are_dubai_abc_almanar_hotel_apartment      dubai  Apr 29 2009   \n",
      "2  are_dubai_abc_almanar_hotel_apartment      dubai  Oct 26 2009   \n",
      "3          are_dubai_admiral_plaza_hotel      dubai   Nov 2 2009   \n",
      "4          are_dubai_admiral_plaza_hotel      dubai   Oct 7 2009   \n",
      "\n",
      "                                        hotel_review  \n",
      "0  Just came back after a week at this hotel. The...  \n",
      "1  Room was nice and modern. Had reasonable size ...  \n",
      "2                 May 11 2008 \\tEher 3* als 5*-Hotel  \n",
      "3  It was a good experience as the Hotel was situ...  \n",
      "4  Good hotel offering value for money. Breakfast...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "data = pd.read_csv('dubai_derlenmis_reviews.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\megeb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\megeb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK data files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "data['hotel_review'] = data['hotel_review'].fillna('')\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase the text\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)  # Remove punctuation\n",
    "    text = re.sub(\"\\d+\", \"\", text)  # Remove numbers\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords\n",
    "    return tokens\n",
    "\n",
    "# Apply the preprocessing function to the 'hotel_review' column\n",
    "data['tokens'] = data['hotel_review'].apply(preprocess_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load GloVe embeddings\n",
    "def load_glove_embeddings(glove_file):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "glove_file ='glovetxt/glove.6B.100d.txt'\n",
    "embeddings_index = load_glove_embeddings(glove_file)\n",
    "\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to calculate sentiment score for a review based on GloVe embeddings and VADER\n",
    "def sentiment_score(tokens, embeddings_index):\n",
    "    sentiment = 0\n",
    "    valid_tokens = 0\n",
    "    for word in tokens:\n",
    "        if word in embeddings_index:\n",
    "            sentiment += sid.polarity_scores(word)['compound']\n",
    "            valid_tokens += 1\n",
    "    return sentiment / valid_tokens if valid_tokens > 0 else 0\n",
    "\n",
    "# Apply the sentiment score function to each review\n",
    "data['sentiment_score'] = data['tokens'].apply(lambda tokens: sentiment_score(tokens, embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['cleanliness', 'room', 'service', 'location', 'value', 'safety', 'comfort', 'transportation', 'noise']\n",
    "\n",
    "# Example keyword mapping for each attribute (this can be expanded)\n",
    "attribute_keywords = {\n",
    "    'cleanliness': ['clean', 'dirty', 'hygiene'],\n",
    "    'room': ['room', 'suite', 'bed', 'space'],\n",
    "    'service': ['service', 'staff', 'helpful', 'rude'],\n",
    "    'location': ['location', 'area', 'near', 'far'],\n",
    "    'value': ['value', 'price', 'cost', 'expensive', 'cheap'],\n",
    "    'safety': ['safety', 'secure', 'dangerous'],\n",
    "    'comfort': ['comfort', 'comfortable', 'uncomfortable'],\n",
    "    'transportation': ['transportation', 'bus', 'train', 'subway'],\n",
    "    'noise': ['noise', 'quiet', 'loud']\n",
    "}\n",
    "\n",
    "# Function to calculate sentiment score for each attribute\n",
    "def attribute_sentiment_score(tokens, attribute_keywords, embeddings_index):\n",
    "    sentiment = 0\n",
    "    valid_tokens = 0\n",
    "    for word in tokens:\n",
    "        if word in attribute_keywords:\n",
    "            sentiment += sid.polarity_scores(word)['compound']\n",
    "            valid_tokens += 1\n",
    "    return sentiment / valid_tokens if valid_tokens > 0 else 0\n",
    "\n",
    "# Apply the function to each attribute\n",
    "for attribute in attributes:\n",
    "    data[f'{attribute}_sentiment_score'] = data['tokens'].apply(lambda tokens: attribute_sentiment_score(tokens, attribute_keywords[attribute], embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   hotel_name  weighted_score\n",
      "1142                    are_dubai_ascot_hotel        1.189490\n",
      "9321             are_dubai_rimal_rotana_dubai        1.087490\n",
      "8595                 are_dubai_panorama_deira        1.087490\n",
      "2765              are_dubai_flora_grand_hotel        0.999815\n",
      "3183  are_dubai_golden_sands_hotel_apartments        0.999815\n"
     ]
    }
   ],
   "source": [
    "def recommend_hotels(city, preferences, data):\n",
    "    # Filter by city\n",
    "    city_data = data[data['hotel_city'].str.lower() == city.lower()]\n",
    "    \n",
    "    # Calculate a weighted score based on user preferences\n",
    "    city_data['weighted_score'] = 0\n",
    "    for attribute, weight in preferences.items():\n",
    "        city_data['weighted_score'] += city_data[f'{attribute}_sentiment_score'] * weight\n",
    "    \n",
    "    # Sort by weighted score and return top recommendations\n",
    "    recommended_hotels = city_data.sort_values(by='weighted_score', ascending=False)\n",
    "    return recommended_hotels\n",
    "\n",
    "# Example usage:\n",
    "city = 'dubai'\n",
    "preferences = {\n",
    "    'cleanliness': 1.0,\n",
    "    'room': 0.8,\n",
    "    'service': 0.9,\n",
    "    'location': 0.7,\n",
    "    'value': 0.6,\n",
    "    'safety': 0.5,\n",
    "    'comfort': 0.4,\n",
    "    'transportation': 0.3,\n",
    "    'noise': 0.2\n",
    "}\n",
    "\n",
    "recommendations = recommend_hotels(city, preferences, data)\n",
    "print(recommendations[['hotel_name', 'weighted_score']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
