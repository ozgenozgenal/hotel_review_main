{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absa_tokenizer = AutoTokenizer.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "absa_model = AutoModelForSequenceClassification.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "absa_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_reviews, aspect):\n",
    "    aspect_reviews = [f\"{aspect}: {review}\" for review in batch_reviews]\n",
    "    inputs = absa_tokenizer(aspect_reviews, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = absa_model(**inputs)\n",
    "    probs = F.softmax(outputs.logits, dim=-1)\n",
    "    return probs.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_keywords = {\n",
    "    'cleanliness': ['clean', 'dirty', 'smell', 'stink', 'stunk', 'filthy'],\n",
    "    'room': ['room', 'bed', 'suite', 'large'],\n",
    "    'service': ['service', 'staff', 'help', 'support'],\n",
    "    'location': ['location', 'close', 'area', 'far'],\n",
    "    'value': ['value', 'worth', 'price', 'cost'],\n",
    "    'safety': ['safe', 'safety', 'secure', 'danger', 'dangerous', 'security'],\n",
    "    'comfort': ['comfort', 'comfortable', 'uncomfortable'],\n",
    "    'transportation': ['bus', 'metro', 'station', 'close', 'walk', 'transport', 'transportation'],\n",
    "    'noise': ['sound', 'volume', 'noisy', 'noise', 'silent']\n",
    "}\n",
    "\n",
    "weights = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "\n",
    "def is_aspect_mentioned(review, aspect):\n",
    "    keywords = aspect_keywords[aspect]\n",
    "    return any(keyword in review for keyword in keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_reviews, aspect):\n",
    "    aspect_reviews = [f\"{aspect}: {review}\" for review in batch_reviews]\n",
    "    inputs = absa_tokenizer(aspect_reviews, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = absa_model(**inputs)\n",
    "    probs = F.softmax(outputs.logits, dim=-1)\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "def is_aspect_mentioned(review, aspect):\n",
    "    keywords = aspect_keywords[aspect]\n",
    "    return any(keyword in review for keyword in keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_reviews_for_aspect(df_chunk, aspect, batch_size=16):\n",
    "    logging.info(f\"Processing {aspect} for chunk with size {len(df_chunk)}\")\n",
    "    scores = []\n",
    "    for i in range(0, len(df_chunk), batch_size):\n",
    "        batch_reviews = df_chunk['processed_review'][i:i + batch_size]\n",
    "        logging.info(f\"Processing batch {i // batch_size + 1}/{len(df_chunk) // batch_size + 1} for aspect: {aspect}\")\n",
    "        aspect_mentioned = [is_aspect_mentioned(review, aspect) for review in batch_reviews]\n",
    "        \n",
    "        logging.info(f\"Aspect mentioned in batch: {aspect_mentioned.count(True)}\")\n",
    "        logging.info(f\"Aspect not mentioned in batch: {aspect_mentioned.count(False)}\")\n",
    "        \n",
    "        if any(aspect_mentioned):\n",
    "            logging.info(f\"Aspect {aspect} mentioned in batch {i // batch_size + 1}\")\n",
    "            filtered_reviews = [review for review, mentioned in zip(batch_reviews, aspect_mentioned) if mentioned]\n",
    "            probs = process_batch(filtered_reviews, aspect)\n",
    "            batch_scores = [sum(weights[sentiment] * probs[j, k] for k, sentiment in enumerate(['negative', 'neutral', 'positive'])) for j in range(len(probs))]\n",
    "            # Assign scores to the correct indices\n",
    "            full_batch_scores = []\n",
    "            idx = 0\n",
    "            for mentioned in aspect_mentioned:\n",
    "                if mentioned:\n",
    "                    full_batch_scores.append(batch_scores[idx])\n",
    "                    idx += 1\n",
    "                else:\n",
    "                    full_batch_scores.append(0)\n",
    "            scores.extend(full_batch_scores)\n",
    "        else:\n",
    "            logging.info(f\"Aspect {aspect} not mentioned in batch {i // batch_size + 1}\")\n",
    "            scores.extend([0] * len(batch_reviews))\n",
    "    \n",
    "    logging.info(f\"Total processed scores length: {len(scores)}, chunk length: {len(df_chunk)}\")\n",
    "    \n",
    "    df_chunk[f'{aspect}_score'] = scores\n",
    "    logging.info(f\"Finished processing {aspect} for chunk\")\n",
    "    return df_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_process(df, aspects, batch_size=16):\n",
    "    logging.info(f\"Starting parallel processing with {cpu_count()} CPUs\")\n",
    "    df_split = np.array_split(df, cpu_count())\n",
    "    pool = Pool(cpu_count())\n",
    "    results = []\n",
    "    for chunk in df_split:\n",
    "        for aspect in aspects:\n",
    "            result = pool.apply_async(process_reviews_for_aspect, args=(chunk, aspect, batch_size))\n",
    "            results.append(result)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    combined_results = pd.concat([result.get() for result in results])\n",
    "    logging.info(\"Finished parallel processing\")\n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and tokenizer\n",
    "absa_tokenizer = AutoTokenizer.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "absa_model = AutoModelForSequenceClassification.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "\n",
    "# Check if GPU is available and set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "absa_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_keywords = {\n",
    "    'cleanliness': ['clean', 'dirty', 'smell', 'stink', 'stunk', 'filthy'],\n",
    "    'room': ['room', 'bed', 'suite', 'large'],\n",
    "    'service': ['service', 'staff', 'help', 'support'],\n",
    "    'location': ['location', 'close', 'area', 'far'],\n",
    "    'value': ['value', 'worth', 'price', 'cost'],\n",
    "    'safety': ['safe', 'safety', 'secure', 'danger', 'dangerous', 'security'],\n",
    "    'comfort': ['comfort', 'comfortable', 'uncomfortable'],\n",
    "    'transportation': ['bus', 'metro', 'station', 'close', 'walk', 'transport', 'transportation'],\n",
    "    'noise': ['sound', 'volume', 'noisy', 'noise', 'silent']\n",
    "}\n",
    "\n",
    "weights = {'negative': -1, 'neutral': 0, 'positive': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_reviews, aspect):\n",
    "    aspect_reviews = [f\"{aspect}: {review}\" for review in batch_reviews]\n",
    "    inputs = absa_tokenizer(aspect_reviews, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = absa_model(**inputs)\n",
    "    probs = F.softmax(outputs.logits, dim=-1)\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "def is_aspect_mentioned(review, aspect):\n",
    "    keywords = aspect_keywords[aspect]\n",
    "    return any(keyword in review for keyword in keywords)\n",
    "\n",
    "def process_reviews_for_aspect(df_chunk, aspect, batch_size=16):\n",
    "    logging.info(f\"Processing {aspect} for chunk with size {len(df_chunk)}\")\n",
    "    scores = []\n",
    "    for i in range(0, len(df_chunk), batch_size):\n",
    "        batch_reviews = df_chunk['processed_review'][i:i + batch_size]\n",
    "        logging.info(f\"Processing batch {i // batch_size + 1}/{(len(df_chunk) // batch_size) + 1} for aspect: {aspect}\")\n",
    "        aspect_mentioned = [is_aspect_mentioned(review, aspect) for review in batch_reviews]\n",
    "        \n",
    "        logging.info(f\"Aspect mentioned in batch: {aspect_mentioned.count(True)}\")\n",
    "        logging.info(f\"Aspect not mentioned in batch: {aspect_mentioned.count(False)}\")\n",
    "        \n",
    "        if any(aspect_mentioned):\n",
    "            logging.info(f\"Aspect {aspect} mentioned in batch {i // batch_size + 1}\")\n",
    "            filtered_reviews = [review for review, mentioned in zip(batch_reviews, aspect_mentioned) if mentioned]\n",
    "            probs = process_batch(filtered_reviews, aspect)\n",
    "            batch_scores = [sum(weights[sentiment] * probs[j, k] for k, sentiment in enumerate(['negative', 'neutral', 'positive'])) for j in range(len(probs))]\n",
    "            # Assign scores to the correct indices\n",
    "            full_batch_scores = []\n",
    "            idx = 0\n",
    "            for mentioned in aspect_mentioned:\n",
    "                if mentioned:\n",
    "                    full_batch_scores.append(batch_scores[idx])\n",
    "                    idx += 1\n",
    "                else:\n",
    "                    full_batch_scores.append(0)\n",
    "            scores.extend(full_batch_scores)\n",
    "        else:\n",
    "            logging.info(f\"Aspect {aspect} not mentioned in batch {i // batch_size + 1}\")\n",
    "            scores.extend([0] * len(batch_reviews))\n",
    "    \n",
    "    logging.info(f\"Total processed scores length: {len(scores)}, chunk length: {len(df_chunk)}\")\n",
    "    \n",
    "    df_chunk[f'{aspect}_score'] = scores\n",
    "    logging.info(f\"Finished processing {aspect} for chunk\")\n",
    "    return df_chunk\n",
    "\n",
    "def parallel_process(df, aspects, batch_size=16):\n",
    "    logging.info(f\"Starting parallel processing with {cpu_count()} CPUs\")\n",
    "    df_split = np.array_split(df, cpu_count())\n",
    "    pool = Pool(cpu_count())\n",
    "    results = []\n",
    "    for chunk in df_split:\n",
    "        for aspect in aspects:\n",
    "            logging.info(f\"Submitting task for chunk size {len(chunk)} and aspect {aspect}\")\n",
    "            result = pool.apply_async(process_reviews_for_aspect, args=(chunk, aspect, batch_size))\n",
    "            results.append(result)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    logging.info(\"All tasks completed, combining results\")\n",
    "    combined_results = pd.concat([result.get() for result in results])\n",
    "    logging.info(\"Finished parallel processing\")\n",
    "    return combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\durud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\durud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\durud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "2024-05-15 16:58:20,597 - INFO - Loading data\n",
      "2024-05-15 16:58:20,604 - INFO - Starting parallel processing of reviews\n",
      "2024-05-15 16:58:20,604 - INFO - Starting parallel processing with 12 CPUs\n",
      "c:\\Users\\durud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "2024-05-15 16:58:20,699 - INFO - Submitting task for chunk size 8 and aspect cleanliness\n",
      "2024-05-15 16:58:20,700 - INFO - Submitting task for chunk size 8 and aspect room\n",
      "2024-05-15 16:58:20,702 - INFO - Submitting task for chunk size 8 and aspect service\n",
      "2024-05-15 16:58:20,703 - INFO - Submitting task for chunk size 8 and aspect location\n",
      "2024-05-15 16:58:20,704 - INFO - Submitting task for chunk size 8 and aspect value\n",
      "2024-05-15 16:58:20,705 - INFO - Submitting task for chunk size 8 and aspect safety\n",
      "2024-05-15 16:58:20,706 - INFO - Submitting task for chunk size 8 and aspect comfort\n",
      "2024-05-15 16:58:20,707 - INFO - Submitting task for chunk size 8 and aspect transportation\n",
      "2024-05-15 16:58:20,708 - INFO - Submitting task for chunk size 8 and aspect noise\n",
      "2024-05-15 16:58:20,710 - INFO - Submitting task for chunk size 8 and aspect cleanliness\n",
      "2024-05-15 16:58:20,711 - INFO - Submitting task for chunk size 8 and aspect room\n",
      "2024-05-15 16:58:20,712 - INFO - Submitting task for chunk size 8 and aspect service\n",
      "2024-05-15 16:58:20,713 - INFO - Submitting task for chunk size 8 and aspect location\n",
      "2024-05-15 16:58:20,714 - INFO - Submitting task for chunk size 8 and aspect value\n",
      "2024-05-15 16:58:20,715 - INFO - Submitting task for chunk size 8 and aspect safety\n",
      "2024-05-15 16:58:20,716 - INFO - Submitting task for chunk size 8 and aspect comfort\n",
      "2024-05-15 16:58:20,718 - INFO - Submitting task for chunk size 8 and aspect transportation\n",
      "2024-05-15 16:58:20,719 - INFO - Submitting task for chunk size 8 and aspect noise\n",
      "2024-05-15 16:58:20,720 - INFO - Submitting task for chunk size 8 and aspect cleanliness\n",
      "2024-05-15 16:58:20,721 - INFO - Submitting task for chunk size 8 and aspect room\n",
      "2024-05-15 16:58:20,722 - INFO - Submitting task for chunk size 8 and aspect service\n",
      "2024-05-15 16:58:20,723 - INFO - Submitting task for chunk size 8 and aspect location\n",
      "2024-05-15 16:58:20,725 - INFO - Submitting task for chunk size 8 and aspect value\n",
      "2024-05-15 16:58:20,727 - INFO - Submitting task for chunk size 8 and aspect safety\n",
      "2024-05-15 16:58:20,728 - INFO - Submitting task for chunk size 8 and aspect comfort\n",
      "2024-05-15 16:58:20,730 - INFO - Submitting task for chunk size 8 and aspect transportation\n",
      "2024-05-15 16:58:20,730 - INFO - Submitting task for chunk size 8 and aspect noise\n",
      "2024-05-15 16:58:20,732 - INFO - Submitting task for chunk size 7 and aspect cleanliness\n",
      "2024-05-15 16:58:20,733 - INFO - Submitting task for chunk size 7 and aspect room\n",
      "2024-05-15 16:58:20,734 - INFO - Submitting task for chunk size 7 and aspect service\n",
      "2024-05-15 16:58:20,736 - INFO - Submitting task for chunk size 7 and aspect location\n",
      "2024-05-15 16:58:20,737 - INFO - Submitting task for chunk size 7 and aspect value\n",
      "2024-05-15 16:58:20,738 - INFO - Submitting task for chunk size 7 and aspect safety\n",
      "2024-05-15 16:58:20,739 - INFO - Submitting task for chunk size 7 and aspect comfort\n",
      "2024-05-15 16:58:20,740 - INFO - Submitting task for chunk size 7 and aspect transportation\n",
      "2024-05-15 16:58:20,742 - INFO - Submitting task for chunk size 7 and aspect noise\n",
      "2024-05-15 16:58:20,743 - INFO - Submitting task for chunk size 7 and aspect cleanliness\n",
      "2024-05-15 16:58:20,745 - INFO - Submitting task for chunk size 7 and aspect room\n",
      "2024-05-15 16:58:20,746 - INFO - Submitting task for chunk size 7 and aspect service\n",
      "2024-05-15 16:58:20,748 - INFO - Submitting task for chunk size 7 and aspect location\n",
      "2024-05-15 16:58:20,748 - INFO - Submitting task for chunk size 7 and aspect value\n",
      "2024-05-15 16:58:20,750 - INFO - Submitting task for chunk size 7 and aspect safety\n",
      "2024-05-15 16:58:20,751 - INFO - Submitting task for chunk size 7 and aspect comfort\n",
      "2024-05-15 16:58:20,752 - INFO - Submitting task for chunk size 7 and aspect transportation\n",
      "2024-05-15 16:58:20,754 - INFO - Submitting task for chunk size 7 and aspect noise\n",
      "2024-05-15 16:58:20,754 - INFO - Submitting task for chunk size 7 and aspect cleanliness\n",
      "2024-05-15 16:58:20,756 - INFO - Submitting task for chunk size 7 and aspect room\n",
      "2024-05-15 16:58:20,757 - INFO - Submitting task for chunk size 7 and aspect service\n",
      "2024-05-15 16:58:20,758 - INFO - Submitting task for chunk size 7 and aspect location\n",
      "2024-05-15 16:58:20,759 - INFO - Submitting task for chunk size 7 and aspect value\n",
      "2024-05-15 16:58:20,760 - INFO - Submitting task for chunk size 7 and aspect safety\n",
      "2024-05-15 16:58:20,762 - INFO - Submitting task for chunk size 7 and aspect comfort\n",
      "2024-05-15 16:58:20,763 - INFO - Submitting task for chunk size 7 and aspect transportation\n",
      "2024-05-15 16:58:20,764 - INFO - Submitting task for chunk size 7 and aspect noise\n",
      "2024-05-15 16:58:20,766 - INFO - Submitting task for chunk size 7 and aspect cleanliness\n",
      "2024-05-15 16:58:20,768 - INFO - Submitting task for chunk size 7 and aspect room\n",
      "2024-05-15 16:58:20,769 - INFO - Submitting task for chunk size 7 and aspect service\n",
      "2024-05-15 16:58:20,770 - INFO - Submitting task for chunk size 7 and aspect location\n",
      "2024-05-15 16:58:20,772 - INFO - Submitting task for chunk size 7 and aspect value\n",
      "2024-05-15 16:58:20,773 - INFO - Submitting task for chunk size 7 and aspect safety\n",
      "2024-05-15 16:58:20,774 - INFO - Submitting task for chunk size 7 and aspect comfort\n",
      "2024-05-15 16:58:20,775 - INFO - Submitting task for chunk size 7 and aspect transportation\n",
      "2024-05-15 16:58:20,777 - INFO - Submitting task for chunk size 7 and aspect noise\n",
      "2024-05-15 16:58:20,778 - INFO - Submitting task for chunk size 7 and aspect cleanliness\n",
      "2024-05-15 16:58:20,780 - INFO - Submitting task for chunk size 7 and aspect room\n",
      "2024-05-15 16:58:20,780 - INFO - Submitting task for chunk size 7 and aspect service\n",
      "2024-05-15 16:58:20,781 - INFO - Submitting task for chunk size 7 and aspect location\n",
      "2024-05-15 16:58:20,783 - INFO - Submitting task for chunk size 7 and aspect value\n",
      "2024-05-15 16:58:20,785 - INFO - Submitting task for chunk size 7 and aspect safety\n",
      "2024-05-15 16:58:20,785 - INFO - Submitting task for chunk size 7 and aspect comfort\n",
      "2024-05-15 16:58:20,786 - INFO - Submitting task for chunk size 7 and aspect transportation\n",
      "2024-05-15 16:58:20,788 - INFO - Submitting task for chunk size 7 and aspect noise\n",
      "2024-05-15 16:58:20,788 - INFO - Submitting task for chunk size 7 and aspect cleanliness\n",
      "2024-05-15 16:58:20,789 - INFO - Submitting task for chunk size 7 and aspect room\n",
      "2024-05-15 16:58:20,791 - INFO - Submitting task for chunk size 7 and aspect service\n",
      "2024-05-15 16:58:20,793 - INFO - Submitting task for chunk size 7 and aspect location\n",
      "2024-05-15 16:58:20,794 - INFO - Submitting task for chunk size 7 and aspect value\n",
      "2024-05-15 16:58:20,795 - INFO - Submitting task for chunk size 7 and aspect safety\n",
      "2024-05-15 16:58:20,797 - INFO - Submitting task for chunk size 7 and aspect comfort\n",
      "2024-05-15 16:58:20,798 - INFO - Submitting task for chunk size 7 and aspect transportation\n",
      "2024-05-15 16:58:20,800 - INFO - Submitting task for chunk size 7 and aspect noise\n",
      "2024-05-15 16:58:20,801 - INFO - Submitting task for chunk size 7 and aspect cleanliness\n",
      "2024-05-15 16:58:20,805 - INFO - Submitting task for chunk size 7 and aspect room\n",
      "2024-05-15 16:58:20,813 - INFO - Submitting task for chunk size 7 and aspect service\n",
      "2024-05-15 16:58:20,814 - INFO - Submitting task for chunk size 7 and aspect location\n",
      "2024-05-15 16:58:20,816 - INFO - Submitting task for chunk size 7 and aspect value\n",
      "2024-05-15 16:58:20,817 - INFO - Submitting task for chunk size 7 and aspect safety\n",
      "2024-05-15 16:58:20,818 - INFO - Submitting task for chunk size 7 and aspect comfort\n",
      "2024-05-15 16:58:20,819 - INFO - Submitting task for chunk size 7 and aspect transportation\n",
      "2024-05-15 16:58:20,820 - INFO - Submitting task for chunk size 7 and aspect noise\n",
      "2024-05-15 16:58:20,821 - INFO - Submitting task for chunk size 7 and aspect cleanliness\n",
      "2024-05-15 16:58:20,822 - INFO - Submitting task for chunk size 7 and aspect room\n",
      "2024-05-15 16:58:20,824 - INFO - Submitting task for chunk size 7 and aspect service\n",
      "2024-05-15 16:58:20,825 - INFO - Submitting task for chunk size 7 and aspect location\n",
      "2024-05-15 16:58:20,826 - INFO - Submitting task for chunk size 7 and aspect value\n",
      "2024-05-15 16:58:20,827 - INFO - Submitting task for chunk size 7 and aspect safety\n",
      "2024-05-15 16:58:20,828 - INFO - Submitting task for chunk size 7 and aspect comfort\n",
      "2024-05-15 16:58:20,828 - INFO - Submitting task for chunk size 7 and aspect transportation\n",
      "2024-05-15 16:58:20,830 - INFO - Submitting task for chunk size 7 and aspect noise\n",
      "2024-05-15 16:58:20,831 - INFO - Submitting task for chunk size 7 and aspect cleanliness\n",
      "2024-05-15 16:58:20,832 - INFO - Submitting task for chunk size 7 and aspect room\n",
      "2024-05-15 16:58:20,832 - INFO - Submitting task for chunk size 7 and aspect service\n",
      "2024-05-15 16:58:20,834 - INFO - Submitting task for chunk size 7 and aspect location\n",
      "2024-05-15 16:58:20,835 - INFO - Submitting task for chunk size 7 and aspect value\n",
      "2024-05-15 16:58:20,836 - INFO - Submitting task for chunk size 7 and aspect safety\n",
      "2024-05-15 16:58:20,836 - INFO - Submitting task for chunk size 7 and aspect comfort\n",
      "2024-05-15 16:58:20,837 - INFO - Submitting task for chunk size 7 and aspect transportation\n",
      "2024-05-15 16:58:20,838 - INFO - Submitting task for chunk size 7 and aspect noise\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logging.info(\"Loading data\")\n",
    "    \n",
    "    review_df = pd.read_csv('csv3/processed_reviews2.csv')\n",
    "    \n",
    "    aspects = ['cleanliness', 'room', 'service', 'location', 'value', 'safety', 'comfort', 'transportation', 'noise']\n",
    "    \n",
    "    # Initialize scores with 0\n",
    "    for aspect in aspects:\n",
    "        review_df[f'{aspect}_score'] = 0\n",
    "    \n",
    "    logging.info(\"Starting parallel processing of reviews\")\n",
    "    review_df = parallel_process(review_df, aspects)\n",
    "    \n",
    "    # Save the final DataFrame with overall scores\n",
    "    logging.info(\"Saving overall sentiment scores\")\n",
    "    review_df.to_csv('csv3/overall_sentiment_scores.csv', index=False)\n",
    "    \n",
    "    # Group by hotel_name and hotel_city, then calculate the mean score for each aspect\n",
    "    logging.info(\"Aggregating scores by hotel\")\n",
    "    aggregated_scores = review_df.groupby(['hotel_name', 'hotel_city']).agg({\n",
    "        'cleanliness_score': 'mean',\n",
    "        'room_score': 'mean',\n",
    "        'service_score': 'mean',\n",
    "        'location_score': 'mean',\n",
    "        'value_score': 'mean',\n",
    "        'safety_score': 'mean',\n",
    "        'comfort_score': 'mean',\n",
    "        'transportation_score': 'mean',\n",
    "        'noise_score': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    logging.info(f\"Aggregated scores: {aggregated_scores.head()}\")\n",
    "\n",
    "    logging.info(\"Saving aggregated hotel scores\")\n",
    "    aggregated_scores.to_csv('csv3/aggregated_hotel_scores.csv', index=False)\n",
    "    \n",
    "    logging.info(\"Displaying aggregated hotel scores\")\n",
    "    print(aggregated_scores.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
