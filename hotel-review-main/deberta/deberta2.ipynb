{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import logging\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          hotel_name hotel_city  review_date  \\\n",
      "0  uk_england_london_130_queensgate_london_apartm...  city_data  Aug 14 2007   \n",
      "1  uk_england_london_130_queensgate_london_apartm...  city_data  Oct 17 2006   \n",
      "2  uk_england_london_130_queensgate_london_apartm...  city_data   Aug 9 2006   \n",
      "3  uk_england_london_130_queensgate_london_apartm...  city_data   Aug 8 2006   \n",
      "4  uk_england_london_130_queensgate_london_apartm...  city_data  Jun 12 2006   \n",
      "\n",
      "                                        hotel_review  \n",
      "0  I've stayed at the Queensgate on several occas...  \n",
      "1  We stayed at 130 Queensgate Apartments for 6 d...  \n",
      "2  Having read the reviews on this site, I though...  \n",
      "3  This is a foul hotel. From the dingy, peeling ...  \n",
      "4  130 Queensgate is, as others state, a bit drea...  \n"
     ]
    }
   ],
   "source": [
    "def parse_hotel_reviews(data_dir):\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    # Updated regex pattern to handle flexible spacing and separators\n",
    "    date_pattern = re.compile(r'(\\b(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s\\d{1,2}\\s\\d{4})\\s+([^\\t\\n]*)\\s+(.*)')\n",
    "    data_frames = []\n",
    "\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        city = os.path.basename(root)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            hotel_name = os.path.splitext(file)[0]  # Assuming the file has no extension\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
    "                    content = f.read()\n",
    "\n",
    "                if not content:\n",
    "                    logging.warning(f'File {file_path} is empty.')\n",
    "                    continue\n",
    "\n",
    "                reviews = date_pattern.findall(content)\n",
    "                if not reviews:\n",
    "                    logging.warning(f'No reviews found in file {file_path}. Content: {content[:500]}')\n",
    "                    continue\n",
    "\n",
    "                reviews_data = [{'hotel_name': hotel_name, 'hotel_city': city, 'review_date': date, 'hotel_review': review.strip()} for date, _, title, review in reviews]\n",
    "                if reviews_data:\n",
    "                    data_frames.append(pd.DataFrame(reviews_data))\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f'Error processing file {file_path}: {e}')\n",
    "                continue\n",
    "\n",
    "    if data_frames:\n",
    "        review_df = pd.concat(data_frames, ignore_index=True)\n",
    "    else:\n",
    "        review_df = pd.DataFrame(columns=['hotel_name', 'hotel_city', 'review_date', 'hotel_review'])\n",
    "\n",
    "    return review_df\n",
    "\n",
    "data_dir = 'city_data'\n",
    "review_df = parse_hotel_reviews(data_dir)\n",
    "print(review_df.head())\n",
    "review_df.to_csv('csv_city/derlenmis_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv('csv_city/derlenmis_reviews.csv')\n",
    "review_df = review_df.dropna(subset=['hotel_review'])\n",
    "review_df['processed_review'] = review_df['hotel_review'].str.lower().str.replace('\\t', ' ', regex=False)\n",
    "review_df.to_csv('csv_city/processed_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv('csv_city/processed_reviews.csv')\n",
    "review_df = review_df.drop('hotel_review', axis=1)\n",
    "review_df = review_df.drop('review_date', axis=1)\n",
    "review_df.to_csv('csv_city/processed_reviews2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\durud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\durud\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "absa_tokenizer = AutoTokenizer.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")\n",
    "absa_model = AutoModelForSequenceClassification.from_pretrained(\"yangheng/deberta-v3-base-absa-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "aspects = ['cleanliness', 'room', 'service', 'location', 'value', 'safety', 'comfort', 'transportation', 'noise']\n",
    "weights = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "\n",
    "aspect_keywords = {\n",
    "    'cleanliness': ['clean', 'dirty', 'smell', 'stink', 'stunk', 'filthy'],\n",
    "    'room': ['room', 'bed', 'suite', 'large'],\n",
    "    'service': ['service', 'staff', 'help', 'support'],\n",
    "    'location': ['location', 'close', 'area', 'far'],\n",
    "    'value': ['value', 'worth', 'price'],\n",
    "    'safety': ['safe', 'safety', 'secure', 'danger', 'dangerous'],\n",
    "    'comfort': ['comfort', 'comfortable', 'uncomfortable'],\n",
    "    'transportation': ['bus', 'metro', 'station', 'close', 'walk'],\n",
    "    'noise': ['sound', 'volume', 'noisy', 'noise']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "def process_batch(batch_reviews, aspect):\n",
    "    aspect_reviews = [f\"{aspect}: {review}\" for review in batch_reviews]\n",
    "    inputs = absa_tokenizer(aspect_reviews, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = absa_model(**inputs)\n",
    "    probs = F.softmax(outputs.logits, dim=-1)\n",
    "    return probs.detach().numpy()\n",
    "\n",
    "def is_aspect_mentioned(review, aspect):\n",
    "    keywords = aspect_keywords[aspect]\n",
    "    return any(keyword in review for keyword in keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "review_df = pd.read_csv('csv3/processed_reviews2.csv')\n",
    "# Adding columns for overall sentiment scores\n",
    "for aspect in aspects:\n",
    "    review_df[f'{aspect}_score'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 16:21:05,625 - INFO - Starting processing for aspect: cleanliness\n",
      "Batches for cleanliness:   0%|          | 0/6 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "C:\\Users\\durud\\AppData\\Local\\Temp\\ipykernel_18836\\3124420602.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9822808085009456' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  review_df.at[idx, f'{aspect}_score'] = score\n",
      "Batches for cleanliness: 100%|██████████| 6/6 [00:38<00:00,  6.50s/it]\n",
      "2024-05-15 16:21:44,626 - INFO - Finished processing for aspect: cleanliness\n",
      "2024-05-15 16:21:44,628 - INFO - Starting processing for aspect: room\n",
      "Batches for room:   0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\durud\\AppData\\Local\\Temp\\ipykernel_18836\\3124420602.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5873093456029892' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  review_df.at[idx, f'{aspect}_score'] = score\n",
      "Batches for room: 100%|██████████| 6/6 [02:01<00:00, 20.28s/it]\n",
      "2024-05-15 16:23:46,295 - INFO - Finished processing for aspect: room\n",
      "2024-05-15 16:23:46,300 - INFO - Starting processing for aspect: service\n",
      "Batches for service:   0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\durud\\AppData\\Local\\Temp\\ipykernel_18836\\3124420602.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3562731444835663' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  review_df.at[idx, f'{aspect}_score'] = score\n",
      "Batches for service: 100%|██████████| 6/6 [01:21<00:00, 13.60s/it]\n",
      "2024-05-15 16:25:07,933 - INFO - Finished processing for aspect: service\n",
      "2024-05-15 16:25:07,936 - INFO - Starting processing for aspect: location\n",
      "Batches for location:   0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\durud\\AppData\\Local\\Temp\\ipykernel_18836\\3124420602.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.0605560839176178' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  review_df.at[idx, f'{aspect}_score'] = score\n",
      "Batches for location: 100%|██████████| 6/6 [02:33<00:00, 25.57s/it]\n",
      "2024-05-15 16:27:41,367 - INFO - Finished processing for aspect: location\n",
      "2024-05-15 16:27:41,373 - INFO - Starting processing for aspect: value\n",
      "Batches for value:   0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\durud\\AppData\\Local\\Temp\\ipykernel_18836\\3124420602.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9079222828149796' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  review_df.at[idx, f'{aspect}_score'] = score\n",
      "Batches for value: 100%|██████████| 6/6 [00:31<00:00,  5.18s/it]\n",
      "2024-05-15 16:28:12,485 - INFO - Finished processing for aspect: value\n",
      "2024-05-15 16:28:12,486 - INFO - Starting processing for aspect: safety\n",
      "Batches for safety:   0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\durud\\AppData\\Local\\Temp\\ipykernel_18836\\3124420602.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.9176621846854687' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  review_df.at[idx, f'{aspect}_score'] = score\n",
      "Batches for safety: 100%|██████████| 6/6 [00:07<00:00,  1.32s/it]\n",
      "2024-05-15 16:28:20,404 - INFO - Finished processing for aspect: safety\n",
      "2024-05-15 16:28:20,405 - INFO - Starting processing for aspect: comfort\n",
      "Batches for comfort:   0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\durud\\AppData\\Local\\Temp\\ipykernel_18836\\3124420602.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.9824055470526218' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  review_df.at[idx, f'{aspect}_score'] = score\n",
      "Batches for comfort: 100%|██████████| 6/6 [00:30<00:00,  5.12s/it]\n",
      "2024-05-15 16:28:51,139 - INFO - Finished processing for aspect: comfort\n",
      "2024-05-15 16:28:51,140 - INFO - Starting processing for aspect: transportation\n",
      "Batches for transportation:   0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\durud\\AppData\\Local\\Temp\\ipykernel_18836\\3124420602.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.3537231981754303' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  review_df.at[idx, f'{aspect}_score'] = score\n",
      "Batches for transportation: 100%|██████████| 6/6 [02:05<00:00, 20.86s/it]\n",
      "2024-05-15 16:30:56,285 - INFO - Finished processing for aspect: transportation\n",
      "2024-05-15 16:30:56,289 - INFO - Starting processing for aspect: noise\n",
      "Batches for noise:   0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\durud\\AppData\\Local\\Temp\\ipykernel_18836\\3124420602.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.8853177167475224' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  review_df.at[idx, f'{aspect}_score'] = score\n",
      "Batches for noise: 100%|██████████| 6/6 [00:03<00:00,  1.93it/s]\n",
      "2024-05-15 16:30:59,406 - INFO - Finished processing for aspect: noise\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for aspect in aspects:\n",
    "    logging.info(f\"Starting processing for aspect: {aspect}\")\n",
    "    overall_scores = []\n",
    "    for i in tqdm(range(0, len(review_df), batch_size), desc=f\"Batches for {aspect}\"):\n",
    "        batch_reviews = review_df['processed_review'][i:i + batch_size]\n",
    "        aspect_mentioned = [is_aspect_mentioned(review, aspect) for review in batch_reviews]\n",
    "        if any(aspect_mentioned):\n",
    "            probs = process_batch([review for review, mentioned in zip(batch_reviews, aspect_mentioned) if mentioned], aspect)\n",
    "            scores = [sum(weights[sentiment] * probs[j, k] for k, sentiment in enumerate(['negative', 'neutral', 'positive'])) for j in range(len(probs))]\n",
    "        else:\n",
    "            scores = [0] * len(batch_reviews)\n",
    "        for idx, score in zip(batch_reviews.index, scores):\n",
    "            review_df.at[idx, f'{aspect}_score'] = score\n",
    "\n",
    "    logging.info(f\"Finished processing for aspect: {aspect}\")\n",
    "\n",
    "# Save the final DataFrame with overall scores\n",
    "review_df.to_csv('deneme/overall_sentiment_scores.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
